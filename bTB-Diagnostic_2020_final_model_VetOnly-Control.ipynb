{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd1ac98-7c57-46b3-9ca0-9b4dfe74e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gp\n",
    "import geoplot\n",
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435fc234-bef8-4f8a-9d70-9615b2357a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import shapely\n",
    "import rtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc72ded-6afc-4705-ab8d-42c3256bf3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier as GBT\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "#from sklearn.utils.fixes import loguniform\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split, cross_validate, GridSearchCV\n",
    "from scipy.stats import randint,uniform,loguniform\n",
    "from sklearn.inspection import PartialDependenceDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62536a34-b964-4bf5-bb81-175568b6b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1e7837-b69f-4a30-acc4-36ed795efe29",
   "metadata": {},
   "source": [
    "---\n",
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260a1ce-8c2a-4324-8d78-0891028f8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Control runs (labels)\n",
    "controls = [1,2,3,4,5]\n",
    "runs = ['vet'] + ['full'] + controls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf17004-07e3-4dd7-844c-9019dd289561",
   "metadata": {},
   "source": [
    "# Load training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1977ad48-146c-4df8-b1d5-8d04fa26fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train/test splits used in training controls\n",
    "X_train = {}\n",
    "X_test = {}\n",
    "y_train = {}\n",
    "y_test = {}\n",
    "for r in controls:\n",
    "    X_train[r], X_test[r], y_train[r], y_test[r] = load('/Data/TB_Diagnostics/final_data_split_VetOnly_Control_'+str(r)+'.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70ebe58-5fa2-43b0-a3d2-4814d6cc42e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train/test splits used in training vet only run\n",
    "r = 'vet'\n",
    "X_train[r], X_test[r], y_train[r], y_test[r] = load('/Data/TB_Diagnostics/final_data_split_VetOnly.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae555eb4-7f28-43ef-8fef-be2d24888f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train/test splits used in training full model\n",
    "r = 'full'\n",
    "X_train[r], X_test[r], y_train[r], y_test[r] = load('/Data/TB_Diagnostics/final_data_split.data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee29cd1-a9b8-44d4-aebc-e7ee91c995ae",
   "metadata": {},
   "source": [
    "# Load original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3a0ef6-a83a-489d-80ec-e8388ab0a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load data\n",
    "data = pd.read_csv('/Data/TB_Diagnostics/inputVars_VetOnly.csv',parse_dates=['dateOfTest'],dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c458044-540f-4a9e-b7d8-e1b6110f5e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target feature (confirmed breakdowns) as binary class\n",
    "data_y = data.confirmedBreakdown.to_numpy().astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a5e8f-2963-466b-87eb-ee95ebe77238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get observed features\n",
    "data_X = data.drop(columns=['confirmedBreakdown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0a512-e740-4352-b1ed-e0ac8698cd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates to float\n",
    "data_X.dateOfTest = data_X.dateOfTest.astype(int).astype(float)\n",
    "# Add Random features\n",
    "data_X['rand'] = np.random.random_sample(len(data_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3a959-c82e-438f-9e7c-8f1097ce8858",
   "metadata": {},
   "source": [
    "# Model scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec9fbc-7654-4fd3-b68b-fbee40cec379",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function: sensitivity(prediction,target)\n",
    "# returns sensitivity of prediction vs. target\n",
    "# Se = TP / (TP + FN)\n",
    "def sensitivity(p,t):\n",
    "    TP = (p&t).sum()\n",
    "    FN = (~p&t).sum()\n",
    "    return TP / (TP + FN)\n",
    "\n",
    "## Function: specificity(prediction,target)\n",
    "# returns specificity of prediction vs. target\n",
    "# Sp = TN / (TN + FP)\n",
    "def specificity(p,t):\n",
    "    TN = (~p&~t).sum()\n",
    "    FP = (p&~t).sum()\n",
    "    return TN / (TN + FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e67834-1086-4273-82f4-aaa79426d31e",
   "metadata": {},
   "source": [
    "### SICCT Test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e767706d-81c9-447b-a7a4-7780a7d68b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "sicct = {}\n",
    "Se_sicct = {}\n",
    "Sp_sicct = {}\n",
    "Acc_sicct = {}\n",
    "specificity_threshold = {}\n",
    "\n",
    "for r in runs:\n",
    "    sicct[r] = X_test[r][:,1].astype(bool)\n",
    "    ## Sensitivity\n",
    "    Se_sicct[r] = sensitivity(sicct[r],y_test[r])\n",
    "    ## Specificity\n",
    "    Sp_sicct[r] = specificity(sicct[r],y_test[r])\n",
    "    ## Accuracy\n",
    "    Acc_sicct[r] = (sicct[r]==y_test[r]).sum() / len(y_test[r])\n",
    "    # Set specificity threshold to level for SICCT-only prediction\n",
    "    specificity_threshold[r] = Sp_sicct[r]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd52b52-caf6-42bf-9952-855c46d6347b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02aac16-bec1-45f6-8f7c-bc221562f5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load cross-validated and fit model\n",
    "model = {}\n",
    "for r in controls:\n",
    "    model[r] = load('/Data/TB_Diagnostics/final_model_VetOnly_Control_'+str(r)+'.model')\n",
    "    \n",
    "model['vet'] = load('/Data/TB_Diagnostics/final_model_VetOnly.model')\n",
    "model['full'] = load('/Data/TB_Diagnostics/final_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f01840-d148-412d-b355-0a5295c84212",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dcc7f3-e102-4dfb-b7af-343568f8121b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model score on testing set: (score is metric set at training time)\n",
    "for r in controls:\n",
    "    print(model[r].score(X_test[r],y_test[r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90128953-7914-41f5-96be-78dc241971fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get test predictions for more detailed evaluation:\n",
    "y_test_result = {}\n",
    "y_score = {}\n",
    "for r in runs:\n",
    "    y_test_result[r] = model[r].predict(X_test[r])\n",
    "    y_score[r] = model[r].decision_function(X_test[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a9b46-26b7-4510-9b82-096e51c2216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sensitivity\n",
    "Se = {}\n",
    "for r in controls:\n",
    "    Se[r] = sensitivity(y_test_result[r],y_test[r])\n",
    "    print(Se[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd92f58-ebc8-4364-9436-d56d8f1e0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specificity\n",
    "Sp = {}\n",
    "for r in controls:\n",
    "    Sp[r] = specificity(y_test_result[r],y_test[r])\n",
    "    print(Sp[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac84b5d-0ac3-4eea-9856-1e91beef126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy\n",
    "Acc = {}\n",
    "for r in controls:\n",
    "    Acc[r] = (y_test_result[r]==y_test[r]).sum() / len(y_test[r])\n",
    "    print(Acc[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3588c1ad-fc26-4a0f-84b6-4257f6e406c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list(Acc.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a788b3e4-cbf7-4fac-99ce-68273d9aabed",
   "metadata": {},
   "source": [
    "---\n",
    "# ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ec298c-991d-459c-a6c7-668fe091f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for r in controls:\n",
    "    fpr[r], tpr[r], _ = roc_curve(y_test[r],y_score[r])\n",
    "    roc_auc[r] = auc(fpr[r],tpr[r])\n",
    "    print(roc_auc[r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6677e340-fb0a-438c-b05b-fa039cc8bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(list(roc_auc.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ee1fc-8abb-4b7d-8df9-d0fa73109374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#function ot plot roc curve\n",
    "def plot_roc(fpr,tpr,roc_auc,run):\n",
    "    r=run\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    plt.plot(\n",
    "        fpr[r],\n",
    "        tpr[r],\n",
    "        lw=lw,\n",
    "        label=\"Model (AUC = %0.2f)\" % roc_auc[r],\n",
    "    )\n",
    "    plt.plot(1-Sp_sicct[r],Se_sicct[r],'+', label=\"SICCT only\", ms='15')\n",
    "    plt.plot([0, 1], [0, 1], lw=lw, linestyle=\"--\", label='Random')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.0])\n",
    "    plt.xlabel(\"(1 - Specificity)\")\n",
    "    plt.ylabel(\"Sensitivity\")\n",
    "    plt.title(\"Receiver operating characteristic\")\n",
    "    plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f5f3bb-e7a3-4987-a381-6824560d836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "for r in controls:\n",
    "    plot_roc(fpr,tpr,roc_auc,r)\n",
    "    #plt.savefig('../Paper/figs/roc.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0f6f31-b460-4b73-89b0-90edb0302818",
   "metadata": {},
   "source": [
    "---\n",
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b2bcc-5da2-46b3-8a91-9e130fd17a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Calcuate permutation importance\n",
    "importance = {}\n",
    "for r in runs:\n",
    "    importance[r] = permutation_importance(model[r],X_test[r],y_test[r], n_repeats=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80121727-2789-476b-9456-0584686afbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in importance.importances_mean.argsort()[::-1]:\n",
    "#    if abs(importance.importances_mean[i]) - 2 * importance.importances_std[i] > 0:\n",
    "#        print('*',f\"{importance.importances_mean[i]:.5f}\", f\" +/- {importance.importances_std[i]:.5f}\", data_X.columns[i])\n",
    "#    else:\n",
    "#        print(' ',f\"{importance.importances_mean[i]:.5f}\", f\" +/- {importance.importances_std[i]:.5f}\", data_X.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacd01f1-a312-4f1c-a33a-3433e54e4e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform into table\n",
    "importance_table = {}\n",
    "for r in runs:\n",
    "    importance_table[r] = pd.DataFrame(importance[r].importances.T, columns=data_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00152d7d-c5c6-4213-8563-e9519f66a059",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_order = {}\n",
    "mean_order_nozero = {}\n",
    "for r in runs:\n",
    "    mean_order[r] = list(importance_table[r].mean().sort_values(ascending=False).index)\n",
    "    mean_order_nozero[r] = list(importance_table[r].mean()[importance_table[r].mean()>0].sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1606583-aef9-455a-9b5e-2391ed666894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define feature lables:\n",
    "feature_labels = {'resultOfTest':'Herd-level SICCT result',\n",
    "                 'locationY':'Holding location Easting',\n",
    "                 'locationX':'Holding location Northing',\n",
    "                 'daysSinceBreakdown':'Days since herd breakdown *',\n",
    "                 'dateOfTest':'Date of herd SICCT testing',\n",
    "                 'animalsTested':'Number of animals tested',\n",
    "                 'daysSincePreviousTest':'Time since previous SICCT test in herd *',\n",
    "                 'severe':'Was the severe interpretation applied?',\n",
    "                 'previousTestResult':'Result of last previous SICCT test in herd *',\n",
    "                 'previousTestResult2':'Result of 2nd last previous SICCT test in herd *',\n",
    "                 'gammaTestCount':'Number of historical GammaIFN test events in herd',\n",
    "                 'rand':'Set of uniformly distributed random numbers (CONTROL)',\n",
    "                 'inflow1':'Animals moved into herd, 1 year',\n",
    "                 'inflow2':'Animals moved into herd, 2 years',\n",
    "                 'inflow4':'Animals moved into herd, 4 years',\n",
    "                 'inflow90':'Animals moved into herd, 90 days',\n",
    "                 'outflow1':'Animals moved out herd, 1 year',\n",
    "                 'outflow2':'Animals moved out herd, 2 years',\n",
    "                 'outflow4':'Animals moved out herd, 4 years',\n",
    "                 'outflow90':'Animals moved out herd, 90 days',\n",
    "                 'inflowBD1':'Animals moved into herd, 1 year, from recent breakdown herds',\n",
    "                 'inflowBD2':'Animals moved into herd, 2 years, from recent breakdown herds',\n",
    "                 'inflowBD4':'Animals moved into herd, 4 years, from recent breakdown herds',\n",
    "                 'inflowBD90':'Animals moved into herd, 90 days, from recent breakdown herds',\n",
    "                 'outflowBD1':'Animals moved out herd, 1 year, from recent breakdown herds',\n",
    "                 'outflowBD2':'Animals moved out herd, 2 years, from recent breakdown herds',\n",
    "                 'outflowBD4':'Animals moved out herd, 4 years, from recent breakdown herds',\n",
    "                 'outflowBD90':'Animals moved out herd, 90 days, from recent breakdown herds',\n",
    "                 'vetPractice':'Veterinary practice conducting the test **',\n",
    "                 'batchBovine':'Tuberculin batch (bovine) **',\n",
    "                 'batchAvian':'Tuberculin batch (avian) **',\n",
    "                 'testType':'Type of testing event',\n",
    "                 'herdSize':'Size of herd at time of test',\n",
    "                 'herdType':'Herd type (dairy, beef, etc.)',\n",
    "                 'monthOfTest':'Month in which test taken',\n",
    "                 'defraRiskScore':'APHA risk score for herd',\n",
    "                 'meanBadgerAbundance':'Mean badger abundance'}\n",
    "def feature_label(x):\n",
    "    try:\n",
    "        return feature_labels[x]\n",
    "    except KeyError:\n",
    "        return x        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386786c4-ccbc-4695-988c-5088d667af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply labels to mean ordered set\n",
    "mean_order_labels = {}\n",
    "mean_order_nozero_labels = {}\n",
    "for r in runs:\n",
    "    mean_order_labels[r] = list(map(lambda x:feature_label(x), mean_order[r]))\n",
    "    mean_order_nozero_labels[r] = list(map(lambda x:feature_label(x), mean_order_nozero[r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dcff23-3e9f-4e4e-8342-f8ebd8679b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate all control runs:\n",
    "importance_table_agg = pd.concat([importance_table[r] for r in controls],ignore_index=True)\n",
    "mean_order_agg = list(importance_table_agg.mean().sort_values(ascending=False).index)\n",
    "mean_order_labels_agg = list(map(lambda x:feature_label(x), mean_order_agg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990941b-35ed-4461-bcc6-0d20fedc1db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot aggregate rankings over all runs:\n",
    "\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "#fig, ax = plt.subplots(figsize=(16,20))\n",
    "fig, ax = plt.subplots(figsize=(16,20))\n",
    "seaborn.barplot(importance_table_agg[mean_order_agg], orient='h', errorbar='ci', ax=ax)\n",
    "ax.set_yticklabels(mean_order_labels_agg)\n",
    "plt.title('Relative importance of model features (5 Control runs)')\n",
    "#plt.xscale('log')\n",
    "plt.savefig('../Paper/figs/importance-reduced-sample.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292ca64-112b-4226-821c-1b4ad0c81a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_table_agg.mean()['vetPractice']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c6439f-d5d9-46c5-ba1e-cfe09a0d6585",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot for each run:\n",
    "\n",
    "for r in runs:\n",
    "    plt.rcParams.update({'font.size': 28})\n",
    "    fig, ax = plt.subplots(figsize=(16,20))\n",
    "    seaborn.barplot(importance_table[r][mean_order[r]], orient='h', errorbar='ci', ax=ax)\n",
    "    ax.set_yticklabels(mean_order_labels[r])\n",
    "    plt.title('Relative importance of model features')\n",
    "    #plt.xscale('log')\n",
    "    #plt.savefig('../Paper/figs/importance.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f128aa-8d97-4d5a-87d3-33f584c4a833",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in controls:\n",
    "    print(importance_table[r].mean()['vetPractice']*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b81c03e-cf60-40c7-9114-99a607c0df20",
   "metadata": {},
   "source": [
    "## Plot controls against vet only and full model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb90a7b-300b-4387-9ba8-3b1bf0249a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label tables:\n",
    "#importance_table['full']['model'] = 'full'\n",
    "#importance_table['vet']['model'] = 'vet'\n",
    "#importance_table_agg['model'] = 'control'\n",
    "\n",
    "#aggregate\n",
    "#importance_table_forPlot = pd.concat([importance_table['full'],importance_table['vet'],importance_table_agg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1aa99a-967c-4c59-a3dd-411d5cedad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 28})\n",
    "fig, ax = plt.subplots(figsize=(16,20))\n",
    "ord = mean_order['full']\n",
    "seaborn.barplot(importance_table['full'][ord], orient='h', errorbar='ci', ax=ax, label='full', color='red', alpha=0.5)\n",
    "#seaborn.barplot(importance_table['vet'][ord], orient='h', errorbar='ci', ax=ax, label='vet', color='blue', alpha=0.5)\n",
    "ax.set_yticklabels(mean_order_labels['full'])\n",
    "plt.title('Relative importance of model features (all runs)')\n",
    "plt.xscale('log')\n",
    "plt.legend()\n",
    "#plt.savefig('../Paper/figs/importance.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff16a7-5983-40f5-81de-31b714be0918",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_table['full'].melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e160cc-1b15-4b33-8bb2-1f29b25485ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearange tables for plotting grouped bar plot for all three models (full, vet, controls):\n",
    "\n",
    "order_by = 'vet' #order all by full model order\n",
    "ord = mean_order[order_by] \n",
    "ord_labels = mean_order_labels[order_by]\n",
    "\n",
    "t1 = importance_table['full'][ord].melt()\n",
    "t1['model'] = 'full'\n",
    "t2 = importance_table['vet'][ord].melt()\n",
    "t2['model'] = 'vet'\n",
    "t3 = importance_table_agg[ord].melt()\n",
    "t3['model'] = 'control'\n",
    "\n",
    "t_all = pd.concat([t1,t2,t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc69f67-ad40-47e0-9632-0cc0e56b3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all models in grouped bar plot:\n",
    "\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "fig, ax = plt.subplots(figsize=(16,20))\n",
    "seaborn.barplot(ax=ax, data=t_all, x='value', y='variable', hue='model', errorbar='ci')\n",
    "ax.set_yticklabels(ord_labels)\n",
    "plt.title('Relative importance of model features (all models)')\n",
    "#plt.xscale('log')\n",
    "#plt.legend()\n",
    "plt.ylabel(None)\n",
    "plt.xlabel('Relative Importance')\n",
    "#plt.savefig('test.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d4c471-2f52-40e3-8922-7c123713c442",
   "metadata": {},
   "source": [
    "---\n",
    "# Decision threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f14688-94e3-4290-b8d4-01bc49b52619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to apply decision threshold\n",
    "def predict_with_threshold(X, model, decision_threshold):\n",
    "    return model.predict_proba(X)[:,1]>=decision_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c1c89c-47ec-4ca1-a55c-10757085f87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different thresholds\n",
    "thresholds = np.linspace(0.0,1.0,101)\n",
    "sens = np.zeros(len(thresholds)) #sensitivity at threshold\n",
    "spec = np.zeros(len(thresholds)) #specificity at threshold\n",
    "for x in range(len(thresholds)):\n",
    "    y_th = predict_with_threshold(X_test,model,thresholds[x])\n",
    "    sens[x] = sensitivity(y_th,y_test)\n",
    "    spec[x] = specificity(y_th,y_test)\n",
    "\n",
    "best_sens = max(sens[spec >= Sp_sicct]) #sensitivity s.t. specificity >= SICCT\n",
    "best_thresh = min(thresholds[spec >= Sp_sicct]) #threshold with max sensitivity s.t. specificity >= SICCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0391e6cb-5d30-42da-864a-64a39ab56fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})\n",
    "# function to plot thresholds\n",
    "plt.plot(thresholds,sens,label='Model HSe')\n",
    "plt.plot(thresholds,spec,label='Model HSp')\n",
    "plt.xlim(0.2,0.8)\n",
    "plt.ylim(0.5,1.0)\n",
    "best_sens_label = 'Chosen HSe = '+str(round(best_sens*100,1))+'%'\n",
    "sicct_sens_label = 'SICCT HSe = '+str(round(Se_sicct*100,1))+'%'\n",
    "sicct_spec_label = 'SICCT HSp = '+str(round(Sp_sicct*100,1))+'%'\n",
    "best_thresh_label = 'Chosen threshold = '+str(round(best_thresh,3))\n",
    "plt.axvline(best_thresh,c='k',ls='-.',label=best_thresh_label)\n",
    "plt.axhline(best_sens,c='k',ls='--',label=best_sens_label)\n",
    "plt.axhline(Se_sicct,c='tab:blue',ls=':',label=sicct_sens_label)\n",
    "plt.axhline(Sp_sicct,c='tab:orange',ls=':',label=sicct_spec_label)\n",
    "plt.xlabel('Decision Threshold')\n",
    "plt.legend(bbox_to_anchor=(1, 0.5))\n",
    "#plt.savefig('../Paper/figs/decision_threshold.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f5e010-d528-4d1e-89b5-4f0db5ddaca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage increase in sensitivity over SICCT alone\n",
    "(best_sens - Se_sicct)/Se_sicct*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207d271-4edc-400d-875e-9c69d604b6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions from model at threshold\n",
    "y_test_predicted = predict_with_threshold(X_test, model, best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b0bb2-d40e-49c1-a05f-9b0ee7f03533",
   "metadata": {},
   "source": [
    "### Test on 2020 only data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e8fcbc-416b-4034-b09d-7ab1b4604fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for 2020 only\n",
    "mask_2020 = data.dateOfTest.apply(lambda x:x.year)==2020\n",
    "X_2020 = data_X[mask_2020].to_numpy()\n",
    "y_2020 = data_y[mask_2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f7f7b-9bfb-4059-a937-3a687301389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions from model at threshold for 2020 only\n",
    "y_2020_predicted = predict_with_threshold(X_2020, model, best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1a8a42-6c35-45a3-9e4c-de7aec974af0",
   "metadata": {},
   "source": [
    "### Test with HSp maximised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c5dc0-8ccd-422b-a662-55e50d280d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we maximise specificty instead?\n",
    "\n",
    "sens_thresh = max(thresholds[sens>= Se_sicct]) # threshold with max specificity s.t. sensitivity >= SICCT\n",
    "best_spec = max(spec[sens >= Se_sicct]) # specificty s.t. sensitivity >= SICCT\n",
    "\n",
    "sens_thresh , best_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a014bd-6b3e-4c97-bab5-be3071c37204",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions from model at HSp threshold\n",
    "y_test_predicted_hsp = predict_with_threshold(X_test, model, sens_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38850be3-e638-4ef0-abf8-6d75e70751ac",
   "metadata": {},
   "source": [
    "---\n",
    "# <mark>Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f1b2d-197b-4920-8624-881e42490323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Projections:\n",
    "bng = 'epsg:27700' # British National Grid\n",
    "wgs84 = 'epsg:4326' # Lat.Long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20681a9a-e764-4018-9bd8-0ea3c503143f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#UK base map\n",
    "uk_shp = gp.read_file('/Data/Shapefiles/bdline_essh_gb/Data/Supplementary_Country/country_region.shp').to_crs(wgs84)\n",
    "#uk_shp.plot(color='white', edgecolor='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f72d9c-b845-4295-bed9-24da037d64d5",
   "metadata": {},
   "source": [
    "## Plot residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f28e8a-027b-4887-a663-d6af3a56b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = (y_test != y_test_predicted)\n",
    "\n",
    "test_locs = pd.DataFrame({'locationX':X_test[:,5],'locationY':X_test[:,6],'date':X_test[:,0]})\n",
    "test_locs.date = test_locs.date.astype('datetime64[ns]')\n",
    "\n",
    "test_locs['residual'] = residual\n",
    "\n",
    "test_geo = gp.GeoDataFrame(test_locs,geometry=gp.points_from_xy(test_locs.locationX,test_locs.locationY,crs=bng))\n",
    "test_geo = test_geo.to_crs(wgs84)\n",
    "\n",
    "errors = test_geo[test_geo.residual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a4105b-c64c-4f15-a480-8e7b9e5b8f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# residuals for 2020 only\n",
    "residual_2020 = (y_2020 != y_2020_predicted)\n",
    "\n",
    "locs_2020 = pd.DataFrame({'locationX':X_2020[:,5],'locationY':X_2020[:,6],'date':X_2020[:,0]})\n",
    "locs_2020.date = locs_2020.date.astype('datetime64[ns]')\n",
    "\n",
    "locs_2020['residual'] = residual_2020\n",
    "\n",
    "geo_2020 = gp.GeoDataFrame(locs_2020,geometry=gp.points_from_xy(locs_2020.locationX,locs_2020.locationY,crs=bng))\n",
    "geo_2020 = geo_2020.to_crs(wgs84)\n",
    "\n",
    "errors_2020 = geo_2020[geo_2020.residual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a69a1d1-93c9-46a3-a1cc-d61d2dcb638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of observations vs. residuals in Test set\n",
    "ax = uk_shp.plot(alpha=0.2, figsize=(10,20))\n",
    "#test_geo.plot('residual', markersize=1.0, ax=ax)\n",
    "test_geo.plot(markersize=1.0, ax=ax)\n",
    "errors.plot(markersize=1.0, color='red', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6fed6e-e265-444c-a8ff-c2221b0957dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of observations vs. residuals in 2020 set\n",
    "ax = uk_shp.plot(alpha=0.2, figsize=(10,20))\n",
    "geo_2020.plot(markersize=1.0, ax=ax)\n",
    "errors_2020.plot(markersize=1.0, color='red', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf025c-f5b9-4bc5-8d06-9df48399078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals in time\n",
    "test_times = pd.DataFrame({'date':X_test[:,0].copy().astype('datetime64[ns]')})\n",
    "test_times['residual'] = residual\n",
    "error_times = test_times[test_times.residual]\n",
    "e = error_times.groupby(error_times[\"date\"].dt.year).count().date\n",
    "t = test_times.groupby(test_times[\"date\"].dt.year).count().date\n",
    "(e/t).plot.bar()\n",
    "plt.title(\"Proportion of model misclassifications by year\")\n",
    "plt.xlabel('Year')\n",
    "#plt.savefig('../Paper/figs/temporal.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440f57da-101a-4d2d-8120-3d7f31841401",
   "metadata": {},
   "source": [
    "## Plot newly discovered positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf3f8f6-dd51-4767-99d9-1b17e0ec5375",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_detected = (~X_test[:,1].astype(bool) & y_test_predicted)\n",
    "test_geo['new_detected'] = new_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0044411-c380-4245-9fca-5710095bb9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new detected in 2020\n",
    "new_detected_2020 = (~X_2020[:,1].astype(bool) & y_2020_predicted)\n",
    "geo_2020['new_detected'] = new_detected_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a811c36-47d2-4332-8892-acda30a5e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of observations vs. newly detected herds in Test set\n",
    "ax = uk_shp.plot(alpha=0.2, figsize=(10,20))\n",
    "test_geo.plot(markersize=1.0, ax=ax)\n",
    "test_geo[test_geo.new_detected].plot(markersize=1.0, color='gold', ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e5b01-9076-4bca-b7b6-d148da851f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = uk_shp.to_crs(bng).plot(alpha=0.2, figsize=(10,20))\n",
    "seaborn.kdeplot(ax=ax, x=test_geo[test_geo.new_detected].locationX, y=test_geo[test_geo.new_detected].locationY, fill=True, color='gold')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5f9c0-6520-4322-9ffb-c574896fcd03",
   "metadata": {},
   "source": [
    "## Plot Residuals and Newly Detected density by area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20700e-71e5-4093-8739-b9c41e119dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create grid for normalising misclassifcation\n",
    "# total area for the grid\n",
    "xmin, ymin, xmax, ymax = uk_shp.to_crs(bng).total_bounds\n",
    "#size of cell\n",
    "cell_size = 10000 #10km x 10km squares\n",
    "# create the cells in a loop\n",
    "grid_cells = []\n",
    "for x0 in np.arange(xmin, xmax+cell_size, cell_size ):\n",
    "    for y0 in np.arange(ymin, ymax+cell_size, cell_size):\n",
    "        # bounds\n",
    "        x1 = x0-cell_size\n",
    "        y1 = y0+cell_size\n",
    "        grid_cells.append(shapely.geometry.box(x0, y0, x1, y1))\n",
    "grid = gp.GeoDataFrame(grid_cells, columns=['geometry'], crs=bng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd76d332-b6f3-4546-bb96-ecad028ed72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For normalisation of map cells by number of tests in cell:\n",
    "# number of tests in test set\n",
    "grid_n_tests = gp.sjoin(test_geo.to_crs(bng), grid, how='left', predicate='within')\n",
    "grid_n_tests['n_tests'] = 1\n",
    "grid_n_tests_d = grid_n_tests.dissolve(by='index_right', aggfunc='count')\n",
    "grid.loc[grid_n_tests_d.index, 'n_tests'] = grid_n_tests_d.n_tests.values\n",
    "\n",
    "#number of tests in 2002\n",
    "grid_n_tests_2020 = gp.sjoin(geo_2020.to_crs(bng), grid, how='left', predicate='within')\n",
    "grid_n_tests_2020['n_tests20'] = 1\n",
    "grid_n_tests_2020_d = grid_n_tests_2020.dissolve(by='index_right', aggfunc='count')\n",
    "grid.loc[grid_n_tests_2020_d.index, 'n_tests20'] = grid_n_tests_2020_d.n_tests.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57d06ba-c729-4894-b625-00068334487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.plot(column='n_tests')\n",
    "grid.plot(column='n_tests20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265fd8d7-e75f-4bc6-8b9f-386010dbba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spatial join residuals with grid\n",
    "## and plot to produce heatmap\n",
    "errors_grid = gp.sjoin(errors.to_crs(bng), grid, how='left', predicate='within')\n",
    "\n",
    "# Compute residuals per grid cell\n",
    "errors_grid['n_resid'] = 1\n",
    "#errors_grid_d = errors_grid.dissolve(by=\"index_right\", aggfunc=\"count\")\n",
    "errors_grid_n_resid = errors_grid[['index_right','n_resid']].groupby(by=\"index_right\").count()\n",
    "\n",
    "# Add to grid\n",
    "grid.loc[errors_grid_n_resid.index, 'n_resid'] = errors_grid_n_resid\n",
    "\n",
    "# add normalised to grid\n",
    "grid.loc[errors_grid_n_resid.index, 'norm_resid'] = grid.loc[errors_grid_n_resid.index, 'n_resid'] / grid.loc[errors_grid_n_resid.index, 'n_tests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc036b-1972-4b35-8a42-c7312a0b65ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot errors grid\n",
    "ax = grid.plot(column='n_resid', cmap='YlOrRd', legend=True, legend_kwds={'shrink': 0.3}, figsize=(10,20))\n",
    "uk_shp.to_crs(bng).plot(ax=ax,alpha=0.1)\n",
    "plt.title(\"Misclassified tests by area (in test set)\")\n",
    "plt.axis('off')\n",
    "#plt.savefig('../Paper/figs/map_misclassified.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1fa72-f62b-446d-bd70-daf7ba15f364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot errors grid (normalised)\n",
    "ax = grid.plot(column='norm_resid', cmap='YlOrRd', legend=True, legend_kwds={'shrink': 0.3}, figsize=(10,20))\n",
    "uk_shp.to_crs(bng).plot(ax=ax,alpha=0.1)\n",
    "plt.title(\"Proportion of tests misclassified by area (in test set)\")\n",
    "plt.axis('off')\n",
    "#plt.savefig('../Paper/figs/map_misclassified.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06873036-d6d9-4b70-89cb-f404a4374f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute residuals grid for 2020 only\n",
    "errors20_grid = gp.sjoin(errors_2020.to_crs(bng), grid, how='left', predicate='within')\n",
    "\n",
    "# Compute residuals per grid cell\n",
    "errors20_grid['n_resid20'] = 1\n",
    "errors20_grid_n_resid = errors20_grid[['index_right','n_resid20']].groupby(by=\"index_right\").count()\n",
    "\n",
    "# Add to grid\n",
    "grid.loc[errors20_grid_n_resid.index, 'n_resid20'] = errors20_grid_n_resid\n",
    "\n",
    "# add normalised to grid\n",
    "grid.loc[errors20_grid_n_resid.index, 'norm_resid20'] = grid.loc[errors20_grid_n_resid.index, 'n_resid20'] / grid.loc[errors20_grid_n_resid.index, 'n_tests20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b0514-66d3-4af5-a679-046954217c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot errors grid for 2020 only\n",
    "ax = grid.plot(column='n_resid20', cmap='YlOrRd', legend=True, legend_kwds={'shrink': 0.3}, figsize=(10,20))\n",
    "uk_shp.to_crs(bng).plot(ax=ax,alpha=0.1)\n",
    "plt.title(\"Misclassified tests by area (in 2020)\")\n",
    "plt.axis('off')\n",
    "#plt.savefig('../Paper/figs/map_misclassified_2020.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56dc477-b066-4b04-b9e7-4be58b6f871d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot normalised errors grid for 2020 only\n",
    "ax = grid.plot(column='norm_resid20', cmap='YlOrRd', legend=True, legend_kwds={'shrink': 0.3}, figsize=(10,20))\n",
    "uk_shp.to_crs(bng).plot(ax=ax,alpha=0.1)\n",
    "plt.title(\"Proportion of tests misclassified by area (in 2020)\")\n",
    "plt.axis('off')\n",
    "#plt.savefig('../Paper/figs/map_misclassified_2020.pdf',bbox_inches='tight')\n",
    "#plt.savefig('../Paper/figs/map_misclassified_2020.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc2daac-8175-408c-a9c3-1b814c0a539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spatial join newly detected with grid\n",
    "## and plot to produce heatmap\n",
    "new_detect_grid = gp.sjoin(test_geo[test_geo.new_detected].to_crs(bng), grid, how='left', predicate='within')\n",
    "\n",
    "# Compute new detects per grid cell -- aggregate with dissolve\n",
    "new_detect_grid['n_new'] = 1\n",
    "new_detect_grid_n_new = new_detect_grid[['index_right','n_new']].groupby(by=\"index_right\").count()\n",
    "\n",
    "# Add to grid\n",
    "grid.loc[new_detect_grid_n_new.index, 'n_new'] = new_detect_grid_n_new\n",
    "\n",
    "# add normalised to grid\n",
    "grid.loc[new_detect_grid_n_new.index, 'norm_new'] = grid.loc[new_detect_grid_n_new.index, 'n_new'] / grid.loc[new_detect_grid_n_new.index, 'n_tests']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6221042-5b7d-436d-9e39-ad50a5d6e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot new grid\n",
    "ax = grid.plot(column='n_new', cmap='cividis', legend=True, legend_kwds={'shrink': 0.3}, figsize=(10,20))\n",
    "uk_shp.to_crs(bng).plot(ax=ax,alpha=0.1)\n",
    "plt.title(\"Early detected tests by area (in test set)\")\n",
    "plt.axis('off')\n",
    "#plt.savefig('../Paper/figs/map_newly_detected.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd7a9c2-c819-419e-93e9-404ab49472b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.n_new.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c3a5e4-937b-4abd-bf4e-a27c90ba3a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot new grid, normalised\n",
    "ax = grid.plot(column='norm_new', cmap='cividis', legend=True, legend_kwds={'shrink': 0.3}, figsize=(10,20))\n",
    "uk_shp.to_crs(bng).plot(ax=ax,alpha=0.1)\n",
    "plt.title(\"Proportion of tests early detected by area (in test set)\")\n",
    "plt.axis('off')\n",
    "#plt.savefig('../Paper/figs/map_newly_detected.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567de8db-925f-41c3-83f2-7c29208b90e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Spatial join newly detected with grid in 2020 only\n",
    "new_detect20_grid = gp.sjoin(geo_2020[geo_2020.new_detected].to_crs(bng), grid, how='left', predicate='within')\n",
    "\n",
    "# Compute new detects per grid cell -- aggregate with dissolve\n",
    "new_detect20_grid['n_new20'] = 1\n",
    "new_detect20_grid_n_new = new_detect20_grid[['index_right','n_new20']].groupby(by=\"index_right\").count()\n",
    "\n",
    "# Add to grid\n",
    "grid.loc[new_detect20_grid_n_new.index, 'n_new20'] = new_detect20_grid_n_new\n",
    "\n",
    "# add normalised to grid\n",
    "grid.loc[new_detect20_grid_n_new.index, 'norm_new20'] = grid.loc[new_detect20_grid_n_new.index, 'n_new20'] / grid.loc[new_detect20_grid_n_new.index, 'n_tests20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f584801-1387-4272-9971-bfc8f6ebc325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot new grid for 2020 only\n",
    "ax = grid.plot(column='n_new20', cmap='cividis', legend=True, legend_kwds={'shrink': 0.3}, figsize=(10,20))\n",
    "uk_shp.to_crs(bng).plot(ax=ax,alpha=0.1)\n",
    "plt.title(\"Early detected tests by area (in 2020)\")\n",
    "plt.axis('off')\n",
    "#plt.savefig('../Paper/figs/map_newly_detected_2020.pdf',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874e3ba-9215-4b57-bedf-21f98653bc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.n_new20.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c120f9-fa27-462b-91f7-ae873e01ae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot new grid for 2020 only, normalised\n",
    "ax = grid.plot(column='norm_new20', cmap='cividis', legend=True, legend_kwds={'shrink': 0.3}, figsize=(10,20))\n",
    "uk_shp.to_crs(bng).plot(ax=ax,alpha=0.1)\n",
    "plt.title(\"Proportion of tests early detected by area (in 2020)\")\n",
    "plt.axis('off')\n",
    "#plt.savefig('../Paper/figs/map_newly_detected_2020.pdf',bbox_inches='tight')\n",
    "#plt.savefig('../Paper/figs/map_newly_detected_2020.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a329b-0c9e-45c8-a1e1-6ea868e6c438",
   "metadata": {},
   "source": [
    "## Partial dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c6b6a9-e50f-431c-b19e-7783e8150a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Takes ages and eats memory... ?!?!\n",
    "#PartialDependenceDisplay.from_estimator(model, X_train, [4,5,(4,5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19843de4-23f1-4b4b-988e-4e3cd5380308",
   "metadata": {},
   "source": [
    "## Plot feature correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3fc849-0d1c-4b34-8476-d8f9dad0603b",
   "metadata": {},
   "source": [
    "---\n",
    "# <mark>Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2502ddd-f83b-4fd2-aa05-244d7f987292",
   "metadata": {},
   "source": [
    "## What sort of herd is newly detected?\n",
    "\n",
    "* See map above for spatial distribution.\n",
    "* What else?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c5c4bb-b5b3-4482-b558-04c905c12b98",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d9e83-4dbc-4dc7-9db9-8cc3e08416e4",
   "metadata": {},
   "source": [
    "* all stats w.r.t. sicct alone and Stanski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabfe2e7-d1e4-4471-b84d-afde63ea268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([['tp','tn'],['fp','fn']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fbb0e8-9d7d-42aa-84d9-51334f68a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function ot calculate confusion matrix\n",
    "# p = predicted class\n",
    "# t = actual class\n",
    "def confusion_matrix(p,t):\n",
    "    # True Positives\n",
    "    TP = (p&t).sum()\n",
    "    # True Negatives\n",
    "    TN = (~p&~t).sum()\n",
    "    # False Positives\n",
    "    FP = (p&~t).sum()\n",
    "    # False Negatives\n",
    "    FN = (~p&t).sum()\n",
    "    # return matrix (values and proportions)\n",
    "    total = len(p)\n",
    "    val_array = np.array([[TP,TN],[FP,FN]])\n",
    "    prop_array = np.around(np.array([[TP/total, TN/total], [FP/total, FN/total]]) * 100, 1)\n",
    "    return val_array , prop_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387564b-eb96-4115-a389-5803d15f3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix for test set\n",
    "cm_model = confusion_matrix(y_2020_predicted,y_2020)\n",
    "cm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6f3705-701a-4c7d-b3cf-c23271337e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity(y_2020_predicted,y_2020), specificity(y_2020_predicted,y_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc27bf2-231b-4aca-814c-53b939e764cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix for SICCT\n",
    "sicct_2020_predicted = X_2020[:,1]==1\n",
    "cm_sicct = confusion_matrix(sicct_2020_predicted,y_2020)\n",
    "cm_sicct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b235d247-0498-49d8-a1d3-4d191ffb2c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity(sicct_2020_predicted,y_2020), specificity(sicct_2020_predicted,y_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454bc8a-bf69-4f60-b6e6-dfd4773f1100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduction in FNs / FPs from SICCT to model\n",
    "m_fn = cm_model[0][1][1]\n",
    "m_fp = cm_model[0][1][0]\n",
    "s_fn = cm_sicct[0][1][1]\n",
    "s_fp = cm_sicct[0][1][0]\n",
    "\n",
    "print('FN reduction: ', (s_fn - m_fn)/s_fn, '\\nFP reduction:', (s_fp - m_fp)/s_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f490636-f5aa-4262-8e28-c05a98348f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2020 HSe increase: ',(sensitivity(y_2020_predicted,y_2020) - sensitivity(sicct_2020_predicted,y_2020))/sensitivity(sicct_2020_predicted,y_2020))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bd39d1-5099-4ad4-9fde-a54f3aec4ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many FPs caught by HSp maximisation threshold?\n",
    "y_2020_predicted_hse = predict_with_threshold(X_2020, model, sens_thresh)\n",
    "# TNs where test was P, vs. all TNs  (in 2020)\n",
    "sum((X_2020[:,1] == 1) & (y_2020_predicted_hse == 0) & (y_2020 == 0)) , sum((y_2020_predicted_hse == 0) & (y_2020 == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a332ef62-d490-45d8-8540-79b142158479",
   "metadata": {},
   "source": [
    "## Number of days to breakdown (distribution)\n",
    "\n",
    "* for newly detected / vs sicct detected\n",
    "* other? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649fb1d-68a8-49f4-b15f-8ac4567b3cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5dfc972c-248b-41a0-a0c3-764c3869c9b5",
   "metadata": {},
   "source": [
    "## Normalised spatial analysis\n",
    "\n",
    "* residuals normalised by no. of tests\n",
    "* new detections ---\"---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68413072-ebe9-47c7-8af8-a4075b41577d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad6e367d-9bb1-409a-a175-1efdded44533",
   "metadata": {},
   "source": [
    "---\n",
    "# <mark> Other TODOs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb21b12c-8be2-4488-af6b-78e51e0a0bcd",
   "metadata": {},
   "source": [
    "\n",
    "* Permutation importance with multicolinear features\n",
    "* Gold standard period? 90-day or other? Test?\n",
    "* Time / area split models\n",
    "    - Fix fitting to existing model, or re-tune for each model?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
